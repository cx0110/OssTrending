import os
import json
import yaml
import time
import requests
import datetime
from pathlib import Path
from openai import OpenAI

# === 1. é…ç½®ä¸åˆå§‹åŒ– ===
def load_config():
    # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæä¾›é»˜è®¤å€¼
    if not os.path.exists("config.yaml"):
        return {
            "settings": {
                "enable_llm": False,
                "llm_top_n": 5,
                "history_file": "data/history.json",
                "archive_dir": "archives",
                "readme_file": "README.md",
                "readme_header": "# ğŸ“ˆ OSSInsight æ¯æ—¥å¼€æºçƒ­ç‚¹æŠ¥å‘Š\n\n"
            },
            "collections": []
        }
        
    with open("config.yaml", "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)
    
    # ç¯å¢ƒå˜é‡è¦†ç›– (æ”¯æŒ GitHub Actions)
    env_enable_llm = os.environ.get("ENABLE_LLM")
    if env_enable_llm is not None:
        config['settings']['enable_llm'] = (env_enable_llm.lower() == 'true')
        
    return config

# === 2. å†å²ç¼“å­˜ç®¡ç† (çœé’±æ ¸å¿ƒ) ===
def load_history(filepath):
    if not os.path.exists(filepath):
        return {}
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return {}

def save_history(filepath, history):
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

# === 3. æ•°æ®è·å– ===
def fetch_trending(language, period, limit=10):
    url = "https://api.ossinsight.io/q/trending-repos"
    params = {"language": language, "period": period, "format": "json"}
    try:
        print(f"ğŸ“¡ æ­£åœ¨æŠ“å–: {language} ({period})...")
        resp = requests.get(url, params=params, timeout=30)
        resp.raise_for_status()
        data = resp.json().get("data", [])
        
        # --- å…³é”®ä¿®æ”¹ï¼šåœ¨è¿™é‡Œå¼ºåˆ¶æˆªå–å‰ N æ¡ ---
        return data[:limit] 
        
    except Exception as e:
        print(f"âŒ æŠ“å–å¤±è´¥: {e}")
        return []

# === 4. AI æ‘˜è¦ç”Ÿæˆ ===
def generate_ai_summary(client, repo_info, model_name):
    if not client: return ""
    
    name = repo_info.get('repo_name')
    desc = repo_info.get('description', '')
    
    # æ„å»º Prompt
    prompt = (
        f"é¡¹ç›®åç§°: {name}\n"
        f"é¡¹ç›®æè¿°: {desc}\n"
        "è¯·ç”¨ä¸­æ–‡ä¸€å¥è¯æ¦‚æ‹¬è¿™ä¸ªé¡¹ç›®çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œé€šä¿—æ˜“æ‡‚ï¼Œä¸è¦è¶…è¿‡ 50 ä¸ªå­—ã€‚"
    )

    try:
        response = client.chat.completions.create(
            model=model_name, # ä½¿ç”¨é…ç½®çš„æ¨¡å‹åç§° (å¦‚ llama-3.3-70b)
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç²¾é€šå¼€æºæŠ€æœ¯çš„åˆ†æå¸ˆã€‚"},
                {"role": "user", "content": prompt}
            ],
            max_tokens=100,
            temperature=0.3
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"âš ï¸ AI Error: {e}")
        return ""

# === 5. Markdown å†…å®¹æ„å»º ===
def build_markdown_section(title, repos, settings, history, llm_client):
    section = f"## {title}\n\n"
    section += "| æ’å | é¡¹ç›® | Stars | ç®€ä»‹ |\n"
    section += "| :--- | :--- | :--- | :--- |\n"

    for idx, repo in enumerate(repos, 1):
        name = repo['repo_name']
        url = f"https://github.com/{name}"
        stars = repo.get('stars', 0)
        raw_desc = repo.get('description', '').replace('|', '\|').replace('\n', ' ')
        
        final_desc = raw_desc
        # ä½¿ç”¨é…ç½®ä¸­çš„ ai_model
        model_name = settings.get('ai_model', 'gpt-3.5-turbo')

        if idx <= settings.get('llm_top_n', 5) and settings['enable_llm']:
            if name in history:
                final_desc = f"ğŸ¤– {history[name]['summary']}"
            else:
                # ä¼ å…¥ model_name
                ai_summary = generate_ai_summary(llm_client, repo, model_name)
                if ai_summary:
                    final_desc = f"ğŸ¤– {ai_summary}"
                    history[name] = {
                        "summary": ai_summary,
                        "updated_at": datetime.datetime.now().strftime("%Y-%m-%d")
                    }
        
        # æˆªæ–­è¿‡é•¿æè¿°é˜²æ­¢è¡¨æ ¼ç‚¸è£‚
        if len(final_desc) > 150:
            final_desc = final_desc[:147] + "..."

        section += f"| {idx} | [{name}]({url}) | ğŸ”¥ {stars} | {final_desc} |\n"
    
    return section


# === 6. å½’æ¡£ç´¢å¼•æ›´æ–° ===
def get_archives_list(archive_dir):
    if not os.path.exists(archive_dir):
        return []
    
    files = [f for f in os.listdir(archive_dir) if f.endswith('.md')]
    # æŒ‰æ–‡ä»¶å(æ—¥æœŸ)å€’åºæ’åˆ—
    files.sort(reverse=True)
    
    links = []
    for f in files:
        date_str = f.replace('.md', '')
        # ç”Ÿæˆç›¸å¯¹è·¯å¾„é“¾æ¥
        links.append(f"| {date_str} | [æŸ¥çœ‹æŠ¥å‘Š](./{archive_dir}/{f}) |")
    
    return links

# === ä¸»ç¨‹åº ===
def main():
    config = load_config()
    settings = config['settings']
    history = load_history(settings['history_file'])
    
    # åˆå§‹åŒ– LLM (Groq ä¹Ÿæ˜¯ä½¿ç”¨ OpenAI Client)
    llm_client = None
    if settings['enable_llm']:
        api_key = os.environ.get("OPENAI_API_KEY")
        base_url = os.environ.get("OPENAI_BASE_URL")
        if api_key:
            llm_client = OpenAI(api_key=api_key, base_url=base_url)

    # 2. ç”Ÿæˆä»Šæ—¥æŠ¥å‘Šå†…å®¹
    today_str = datetime.datetime.now().strftime("%Y-%m-%d")
    update_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M UTC")
    
    # æŠ¥å‘Šå¤´éƒ¨
    report_content = settings.get('readme_header', "# Daily Report").replace("{{ update_time }}", update_time)
    report_content += f"> æ›´æ–°æ—¶é—´: {update_time}\n\n"

    # éå†é›†åˆæŠ“å–æ•°æ®
    for col in config['collections']:
        # ä¼ å…¥ limit å‚æ•°
        limit = settings.get('top_list_limit', 10)
        repos = fetch_trending(col['language'], col['period'], limit=limit)
        
        if repos:
            section_md = build_markdown_section(col['title'], repos, settings, history, llm_client)
            report_content += section_md + "\n"
        time.sleep(1)

    # 3. ä¿å­˜æ¯æ—¥å½’æ¡£ (archives/202X-XX-XX.md)
    archive_dir = settings['archive_dir']
    os.makedirs(archive_dir, exist_ok=True)
    archive_path = os.path.join(archive_dir, f"{today_str}.md")
    
    with open(archive_path, "w", encoding="utf-8") as f:
        f.write(report_content)
    print(f"âœ… ä»Šæ—¥å½’æ¡£å·²ä¿å­˜: {archive_path}")

    # 4. æ›´æ–°ä¸» README (åŒ…å«ä»Šæ—¥å†…å®¹ + å†å²ç´¢å¼•)
    
    # ç”Ÿæˆå†å²åˆ—è¡¨éƒ¨åˆ†
    archive_links = get_archives_list(archive_dir)
    history_section = "\n\n## ğŸ—„ï¸ å†å²å½’æ¡£ (Archives)\n\n| æ—¥æœŸ | æŠ¥å‘Š |\n| :--- | :--- |\n"
    # åªæ˜¾ç¤ºæœ€è¿‘ 10 æ¡ï¼Œé¿å…ä¸»é¡µå¤ªé•¿ï¼Œæˆ–è€…æ˜¾ç¤ºå…¨éƒ¨
    history_section += "\n".join(archive_links[:14]) # æ˜¾ç¤ºè¿‡å»ä¸¤å‘¨
    if len(archive_links) > 14:
         history_section += f"\n| ... | [æ›´å¤šå†å²](./{archive_dir}) |"

    final_readme = report_content + history_section
    
    with open(settings['readme_file'], "w", encoding="utf-8") as f:
        f.write(final_readme)
    print(f"âœ… README æ›´æ–°æˆåŠŸ")

    # 5. ä¿å­˜ç¼“å­˜
    save_history(settings['history_file'], history)

if __name__ == "__main__":
    main()
